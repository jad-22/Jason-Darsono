<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Jason Darsono | Projects</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../index.html" class="logo"><strong>Jason Darsono</strong></a>
									<ul class="icons">
										<li><a href="mailto:jason.darsono22@imperial.ac.uk" target="_blank" rel="noopener noreferrer" class="icon fa-regular fa-envelope"><span class="label">Email</span></a></li>
										<li><a href="https://www.linkedin.com/in/jasonariyanto" target="_blank" rel="noopener noreferrer" class="icon brands fa-linkedin"><span class="label">Facebook</span></a></li>
										<li><a href="https://github.com/jad-22" target="_blank" rel="noopener noreferrer" class="icon brands fa-github"><span class="label">Snapchat</span></a></li>
										<li><a href="https://medium.com/@jasonadarsono" target="_blank" rel="noopener noreferrer" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
										<li><a href="https://www.instagram.com/jasonariyant/" target="_blank" rel="noopener noreferrer" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Topic Modelling on User Activities</h1>
                                        <blockquote>A user's web journey tells a lot about the user's preferences. By modelling the topic content of the websites visited, we deepen our understanding of the interests of online audiences and potentially perform further user segmentation and/or recommendation.</blockquote>
                                        <p>Retail Marketing Analytics | April 2023</p>
									</header>

									<span class="image main"><img src="project_images/project-1-user-journey.jpg" alt="Topic Modelling User Journey" /></span>
                                    
                                    <ul>
                                        <span>Tags: &nbsp</span>
                                        <li class="action-tag">Natural Language Processing</li>
                                        <li class="action-tag">Web Scraping</li>
                                        <li class="action-tag">Topic Modelling</li>
                                        <li class="skill-tag">Python</li>
                                        <li class="skill-tag">Jupyter Notebook</li>
                                        <li class="skill-tag">PowerPoint</li>
                                    </ul>

									<hr class="minor" style="width: 20%"/>
                                    
									<h2>Motivation - Understanding Online Audiences</h2>
                                    <p>Discovering user profiles in the digital realm is essential for crafting personalised web experiences. While the traditional approach to customer segmentation relies on demographic data, such as age, gender, and income, collecting such information from online users may prove challenging. An alternative strategy centres on users' online behaviours, such as page visits, timing, and active periods. This project delves into these behaviours by extracting key topics from the web content users engage with, also known as topic modelling.</p>
                                    <p>One approach involves manually assigning pre-defined categories to websites, but such a process is extremely time-consuming, particularly when dealing with a large volume of data. Therefore, we need a model capable of autonomously assigning URLs to relevant topics that capture the essence of the respective web pages. The primary goal of this project is to develop a model that can efficiently execute this task with ample speed and accuracy.</p>                                    

									<h2>What is Topic Modelling?</h2>
									<p><strong>Topic modelling is a technique in natural language processing and machine learning used to discover the main topics or themes within a collection of text documents.</strong> It is particularly valuable when dealing with a large amount of unstructured text data, such as articles, books, or social media posts, to understand the prevalent subjects or concepts in the text. One of the most commonly used algorithms for topic modelling is Latent Dirichlet Allocation (LDA). LDA works by analysing the co-occurrence patterns of words in documents to uncover these latent topics.</p>
                                    <p>In this project, we utilise topic modelling to extract information and classify content from various web pages. We will explore LDA, its predecessor Latent Semantic Indexing (LSI), as well as Non-Negative Matrix Factorization (NMF).</p>

									<h2>End-to-end Approach</h2>
									<p>Before modelling the topics, several essential steps should be taken into account both before and after the modeling process. These include tasks like web scraping, text preprocessing, and subsequent topic evaluation.</p>

									<span class="image main"><img src="project_images/project-1-approach.png" alt="Topic Modelling Approach" /></span>
                                    
                                    <h3>Web Scraping</h3>
                                    <p>
                                        To get the content of the web pages, we perform web scraping using the URLs. We use the standard Python library for web scraping <code>requests</code> to retreive web response and then <code>BeautifulSoup</code> to parse specific HTML tags.
                                        We <strong>only retreive web response if the status code is 200</strong> i.e. successful request and focus on relevant tags such as <code>title, headers, p</code>.
                                    <pre><code style="padding-top: 0%; padding-bottom:0%;">
import requests
from bs4 import BeautifulSoup

response = requests.get(url, timeout=5)
if response.status_code == 200:
    content = BeautifulSoup(response.text, 'html.parser')
    content = content.find_all(['title', 'h1', 'h2', 'h3', 'p'])
                                    </code></pre>
                                    </p>

                                    <h3>Text Pre-Processing</h3>
                                    <p>There are three steps involved in processing the texts data before they are ready to be modelled.</p>
                                    
                                    <h4>1. Tokenisation</h4>
                                    <p>
                                        We first split the parsed texts into individual tokens for subsequent processing and analysis.
                                        To tokenise, we can simply split by space delimiter <code>tokens = content.split()</code> which will return a list of tokens.
                                        To perform a cleaner tokenisation along with subsequent processing, we can use <code>gensim</code> package or <code>spacy</code> as such:
                                        <pre><code style="padding-top: 0%; padding-bottom:0%;">
import spacy
from spacy.lang.en import english

# Load SpaCy 'small English' dictionary for parsing text and performing lemmatisation
nlp = spacy.load("en_core_web_sm")
tokenised = English(nlp(content))
                                        </code></pre>
                                    </p>

                                    <h4>2. Normalisation</h4>
                                    <p>
                                        Next, we normalise the tokens by cutting each word to their base form, which can be done via stemming or lemmatisation.
                                        There are several packages and method we explored including NLTK's porter and snowball stemmer, but we found that <strong>SpaCy's lemmas give a slightly better coverage and accuracy</strong>, albeit slower speed.
                                        However, if execution speed is a concern, NLTK's packages would be a better option.
                                    </p>    
                                    <p>We can retreive SpaCy's lemmas as follows:
                                        <pre><code style="padding-top: 0%; padding-bottom:0%;">
lemmas = [token.lemma_.lower().strip() for token in tokenised]
                                        </code></pre>
                                    </p>
                                    
                                    <h4>3. Text Cleaning</h4>
                                    <p>
                                        Lastly, we clean the tokens by removing stopwords from the list of tokens, as well as those with less than 3 characters to reduce redundancy.
                                        We also remove punctuations, numbers and special characters from each token.
                                    </p>
                                    <p>
                                        To get the stopwords, we create a list from NLTK's and SpaCy's stopword corpus. 
                                        <pre><code style="padding-top: 0%; padding-bottom:0%;">
import nltk
from nltk.corpus import stopwords
from spacy.lang.en.stop_words import STOP_WORDS

nltk.download("stopwords")
nltk_stopwords = stopwords.words("english")
spacy_stopwords = list(STOP_WORDS)
all_stopwords = list(set(nltk_stopwords + spacy_stopwords))
                                        </code></pre>
                                    </p>
                                    <p>
                                        To remove punctuations, numbers and special characters, we use regular expression (regex) matching by compiling the patterns.
                                        <pre><code style="padding-top: 0%; padding-bottom:0%;">
import string, re

default_puncs = string.punctuation
special_chars = "â©â£–“”’…"
numbers = "0-9"
pattern = re.compile("[" + default_puncs + special_chars + numbers + "]+")
                                        </code></pre>
                                    </p>
                                    
                                    <p>
                                        We can then use the stopwords and punctuations to clean and finalise the list of tokens:
                                        <pre><code style="padding-top: 0%; padding-bottom:0%;">
cleaned_tokens = [re.sub(pattern, "", token) for token in lemmas 
                    if token not in all_stopwords
                    and token not in list(punctuations)
                    and len(token) >= 3
                    ]
                                        </code></pre>
                                    </p>
                                    
                                    <h3>N-gram modelling</h3>
                                    <p>
                                        Now that the texts data have been tokenised and cleaned, we pass it to N-gram models.
                                        <strong>N-gram models combine multiple tokens into one to form contextual meaning.</strong>
                                        A single token is considered as uni-gram, word-pairs are bi-grams, and so on.
                                        For example, a bi-gram token can be "variable rate", "living cost", etc.
                                        This project utilise bi-gram model as we found that it gave a better performance than uni-gram and tri-gram.
                                    </p>
                                    <p>
                                        To generate bi-gram word-pairs, we use the list of tokens and pass it into <code>gensim</code>'s phrases model.
                                        From the newly generated tokens, we build the id-to-word (id2word) matrix and the bag-of-word (BoW) corpus.
                                        The bag-of-words (BoW) is a vector representation of how many times a token appears in the document, while id-to-word is literally the mapping of token indices to the tokens in the dictionary.
                                        <pre><code style="padding-top: 0%; padding-bottom:0%;">
from gensim import corpora
from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS

# Build bigram phrase model
bigram = Phrases(tokens_list, connector_words=ENGLISH_CONNECTOR_WORDS)

# Generate tokens
bigram_tokens = bigram[tokens_list]

# Create the id-to-word matrix dictionary
id2word = corpora.Dictionary(bigram_tokens)

# Build the bag-of-word (bow) corpus
corpus = [id2word.doc2bow(token) for token in bigram_tokens]
                                        </code></pre>
                                    </p>

                                    <h3>Topic Modelling</h3>
                                    <p>
                                        We then pass the id2word and BoW corpus into the topic modelling algorithm.
                                        We utilise readily available algorithm from <code>gensim</code> (but can also be done using <code>sklearn</code>) as follows:
                                        <pre><code style="padding-top: 0%; padding-bottom:0%;">
from gensim.models import ldamodel

model = ldamodel.LdaModel(
    corpus=corpus,
    id2word=id2word,
    num_topics=6,
    random_state=123
)
                                        </code></pre>
                                        
                                        The parameter <code>num_topics</code> determines the number of latent topic clusters to detect, while fixing <code>random_state</code> allows reproducibility.
                                        Similarly, we can perform topic modelling using non-matrix factorisation (NMF) and latent semantic indexing using <code>from gensim.models import Nmf, lsimodel</code>.
                                    </p>
                                    <p>
                                        <strong>But what is the difference between LDA, NMF and LSI?</strong>
                                        LDA is a more popular approach, because it is a probabilistic
                                    </p>

                                    <h3>Evaluation</h3>
                                    <p>To evaluate the topics, we can perform sample QC to check. </p>

									<h2>Conclusion</h2>
									<p>
                                        Of course the process is not as simple is shown above. 
                                        There are various steps involved which were not mentioned such as data exploration, process selection, model fine-tuning, manual benchmarking, deep-dive and evaluation.
                                        However the steps and processes outlined above captures the general essence of this project.
                                        There are still many more to learn from this project and many more ways to improve on it.
                                    </p>
								</section>

                                <footer id="footer">
                                    <ul class="actions" style="justify-content: center;">
                                        <li><a href="index.html">Back to home</a></li>
                                        <li><a href="#">Back to top</a></li>
                                    </ul>
									<p class="copyright">&copy; Jason Darsono. All rights reserved. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

				<!-- Sidebar -->
                    <div id="sidebar">
                        <div class="inner">
                            
                            <!-- Logo -->
                                <section id="search" class="alt">
                                    <span><img src="../../logos/J_logo_name_75px.png"></span>
                                </section>

                            <!-- Menu -->
                                <nav id="menu">
                                    <header class="major">
                                        <h2>Menu</h2>
                                    </header>
                                    <ul>
                                        <li><a href="../../index.html">Home</a></li>
                                        <li><a href="../../about.html">About Me</a></li>
                                        <li><a href="../../milestone.html">Milestones</a></li>
                                        <li><a href="../../project.html">Projects</a></li>
                                        <li><a href="../../article.html">Articles</a></li>
                                        <li><a href="../../gallery.html">Gallery</a></li>
                                        <li><a href="../../resource.html">Resources</a></li>
                                    </ul>
                                </nav>

                            <!-- Section -->
                                <section>
                                    <header class="major">
                                        <h2>Featured</h2>
                                    </header>
                                    <div class="mini-posts">
                                        <article>
                                            <a href="#" class="image"><img src="../../images/under_construction.jpg" alt="" /></a>
                                            <p>Under construction</p>
                                        </article>
                                        <article>
                                            <a href="#" class="image"><img src="../../images/under_construction.jpg" alt="" /></a>
                                            <p>Under construction</p>
                                        </article>
                                    </div>
                                    <ul class="actions">
                                        <li><a href="#" class="button">More</a></li>
                                    </ul>
                                </section>

                            <!-- Section -->
                                <section>
                                    <header class="major">
                                        <h2>Get in touch</h2>
                                    </header>
                                    <p>Feel free to drop me a message at:</p>
                                    <ul class="contact">
                                        <li class="icon solid fa-envelope"><a href="#">jason.darsono22@imperial.ac.uk</a></li>
                                        <li class="icon solid fa-envelope"><a href="#">jasonadarsono@gmail.com</a></li>
                                        <li class="icon solid fa-home">Preston, Lanchashire<br />
                                        United Kingdom</li>
                                    </ul>

                                    <p>Or connect through my socials:</p>
                                    <ul class="icons">
                                        <li><a href="https://www.linkedin.com/in/jasonariyanto" target="_blank" rel="noopener noreferrer" class="icon brands fa-linkedin"><span class="label">Facebook</span></a></li>
                                        <li><a href="https://github.com/jad-22" target="_blank" rel="noopener noreferrer" class="icon brands fa-github"><span class="label">Snapchat</span></a></li>
                                        <li><a href="https://medium.com/@jasonadarsono" target="_blank" rel="noopener noreferrer" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
                                        <li><a href="https://www.instagram.com/jasonariyant/" target="_blank" rel="noopener noreferrer" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
                                    </ul>
                                </section>

                            <!-- Footer -->
                                <footer id="footer">
                                    <p class="copyright">
                                        &copy; Jason Darsono. All rights reserved. <br />
                                        Design credit: <a href="https://html5up.net">HTML5 UP</a>.
                                    </p>
                                </footer>

                        </div>
                    </div>

            </div>

        <!-- Scripts -->
            <script src="../../assets/js/jquery.min.js"></script>
            <script src="../../assets/js/browser.min.js"></script>
            <script src="../../assets/js/breakpoints.min.js"></script>
            <script src="../../assets/js/util.js"></script>
            <script src="../../assets/js/main.js"></script>
            <script src="https://platform.linkedin.com/badges/js/profile.js" async defer type="text/javascript"></script>

	</body>
</html>